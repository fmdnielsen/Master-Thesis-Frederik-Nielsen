{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e228a33-6784-458c-be3f-121e341d90aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import datetime\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# Tensorflow imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import RepeatVector\n",
    "from keras import regularizers\n",
    "from keras.regularizers import L1L2\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b20a3c-bb64-4c72-8f4e-3609f3b279c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "name = \"error\"\n",
    "n_input = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8771baf-3bb8-42b9-80c9-19f84014bd34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_type = \"ind_week\"\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca585e2d-e4df-4692-b402-d7c44ab7ac3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/work/Master project/data/data_5_clean_lstm.csv\")\n",
    "\n",
    "df = df\n",
    "df = df.set_index('date')\n",
    "\n",
    "num_cols = ['air_temp','humidity','solar_radiation','dew_point_temp']\n",
    "remainder_cols = ['hour_sin','hour_cos','week_sin','week_cos','month_sin','month_cos','day_of_the_week_sin','day_of_the_week_cos','is_weekend' ]\n",
    "\n",
    "print(\"Min Date:\", df.index.min())\n",
    "print(\"Max Date:\", df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079bda0-777f-4663-a0e8-aaa451ebaac3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate performance\n",
    "def performance(name, score, scores):\n",
    " use_scores = ', '.join(['%.1f' % s for s in scores])\n",
    " print('%s: [%.3f] %s' % (name, score, use_scores))\n",
    "    \n",
    " # Creating a dictionary of the data\n",
    " data = {'Model': [name],\n",
    "        'Overall RMSE-score': [score]}\n",
    "\n",
    " # Dynamically create columns for scores\n",
    " data.update({f'RMSE Score {i}': [scores[i-1]] for i in range(1, 25)})\n",
    "\n",
    " # Creating a DataFrame from the dictionary\n",
    " df = pd.DataFrame(data)\n",
    "    \n",
    " # Appending the new data to the DataFrame\n",
    " df.to_csv('LSTM_{}_output.csv'.format(data_type), mode='a', index=False, header=False)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf4e50-d057-449a-803f-f43ef379b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standerdize data\n",
    "def preprocess(X,mean,std,feature):\n",
    "    X.iloc[:,feature] = (X.iloc[:,feature] - mean) / std\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a2ac0-0aa0-4b2d-b1fa-92e8045b74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index, format='%d/%m/%Y %H:%M')\n",
    "data1 = df.loc['2021-01-01 00:00:00': '2023-12-31 23:00:00'].copy()\n",
    "data1.index = pd.to_datetime(data1.index)\n",
    "data1 = data1.resample(\"H\").sum()\n",
    "\n",
    "# Choose colomns\n",
    "data = data1[[\"electricity_cons\",'air_temp', \"hour_sin\", \"hour_cos\", 'day_of_the_week_sin','day_of_the_week_cos','is_weekend', 'month_cos', 'month_sin','week_sin','week_cos']]\n",
    "\n",
    "# Split into train/test sets\n",
    "def split_data(data):\n",
    "    # split into whole days\n",
    "    train_start, train_end = '2021-01-01 12:00:00', '2022-12-31 11:59:00'\n",
    "    test_start, test_end = '2023-01-01 12:00:00', '2023-12-31 11:59:00'\n",
    "    \n",
    "    train = data.loc[train_start:train_end]\n",
    "    test = data.loc[test_start:test_end]\n",
    "\n",
    "     # standerdize data\n",
    "\n",
    "    cons_train_mean = np.mean(train.iloc[:,0])\n",
    "    cons_train_std = np.std(train.iloc[:,0])\n",
    "    train = preprocess(train,cons_train_mean,cons_train_std,0)\n",
    "    test = preprocess(test,cons_train_mean,cons_train_std,0)\n",
    "\n",
    "    air_train_mean = np.mean(train.iloc[:,1])\n",
    "    air_train_std = np.std(train.iloc[:,1])\n",
    "    train = preprocess(train,air_train_mean,air_train_std,1)\n",
    "    test = preprocess(test,air_train_mean,air_train_std,1)\n",
    "\n",
    "    # hum_train_mean = np.mean(train.iloc[:,2])\n",
    "    # hum_train_std = np.std(train.iloc[:,2])\n",
    "    # train = preprocess(train,hum_train_mean,hum_train_std,2)\n",
    "    # test = preprocess(test,hum_train_mean,hum_train_std,2)\n",
    "\n",
    "    # rad_train_mean = np.mean(train.iloc[:,3])\n",
    "    # rad_train_std = np.std(train.iloc[:,3])\n",
    "    # train = preprocess(train,rad_train_mean,rad_train_std,3)\n",
    "    # test = preprocess(test,rad_train_mean,rad_train_std,3)\n",
    "\n",
    "    # temp_train_mean = np.mean(train.iloc[:,4])\n",
    "    # temp_train_std = np.std(train.iloc[:,4])\n",
    "    # train = preprocess(train,temp_train_mean,temp_train_std,4)\n",
    "    # test = preprocess(test,temp_train_mean,temp_train_std,4)\n",
    "   \n",
    "    \n",
    "    \n",
    "    # restructure into windows of daily data\n",
    "    train = array(split(train.values, len(train)/24))\n",
    "    test = array(split(test.values, len(test)/24))\n",
    "\n",
    "    return train, test, cons_train_mean, cons_train_std,  air_train_mean,  air_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb73a7-854e-46ab-b6fa-245974b4bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more daily forecasts against expected values\n",
    "def evaluate_forecast(actual, predicted):\n",
    "    scores = list()\n",
    "    \n",
    "\t# calculate an RMSE score for each hour\n",
    "    for i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "\t\t# store (changede to mse since it otherwise would not make sense on the plot)\n",
    "        scores.append(rmse)\n",
    "    \n",
    "\t# calculate overall RMSE\n",
    "    sum = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            sum += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(sum / (actual.shape[0] * actual.shape[1]))\n",
    "    \n",
    "    # calculate error distribution\n",
    "    error_dist = np.zeros_like(actual, dtype=float)\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            squared_error = (actual[row, col] - predicted[row, col])**2\n",
    "            error_dist[row, col] = sqrt(squared_error)\n",
    "    return score, scores, error_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c2ec8-9f31-468f-8f50-aa487cbe2ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert history into inputs and outputs\n",
    "def to_x_y(train, n_input, n_out=24):\n",
    "    # flatten data\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_start = in_end + 12\n",
    "        out_end = out_start + n_out\n",
    "\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            X.append(data[in_start:in_end, :])\n",
    "            y.append(data[out_start:out_end, 0])\n",
    "\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "\n",
    "    return array(X), array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a27cd3f-5b19-4685-9986-0ce965589b72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM_model(HyperModel):\n",
    "    \n",
    "    def __init__(self, n_input, n_features):\n",
    "        self.n_input = n_input\n",
    "        self.n_features = n_features\n",
    "\n",
    "    def build(self, hp):\n",
    "     # define model\n",
    "     model = tf.keras.Sequential()\n",
    "     activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "     layer_1 = hp.Choice('layer_1', values=[2, 4, 8, 16, 32, 64, 128, 256, 512])\n",
    "     #layer_2 = hp.Choice('layer_2', values=[2, 4, 8, 16, 32, 64, 128, 256, 512])\n",
    "     learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "     model.add(LSTM(units = layer_1, activation=activation, input_shape=(self.n_input, self.n_features), return_sequences=True ))\n",
    "     for i in range(hp.Int('n_layers', 1, 4)):\n",
    "        model.add(LSTM(hp.Choice(f'lstm_{i}_units',values=[2, 4, 8, 16, 32, 64, 128, 256, 512]), return_sequences=True))\n",
    "     model.add(Dropout(hp.Float('Dropout_rate_1',min_value=0,max_value=0.5,step=0.1)))\n",
    "     model.add(LSTM(hp.Choice('layer_2_neurons',values=[2, 4, 8, 16, 32, 64, 128, 256, 512])))\n",
    "     model.add(Dropout(hp.Float('Dropout_rate_2',min_value=0,max_value=0.5,step=0.1)))\n",
    "     model.add(tf.keras.layers.Dense(24))\n",
    "     model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "     return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [8, 16, 32, 64]),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e80a9-785c-4969-989d-1b8edb6c3aea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tuner(train, n_input):\n",
    "\n",
    " # prepare data\n",
    " train_x, train_y = to_x_y(train, n_input)\n",
    "    \n",
    " n_features = train_x.shape[2]\n",
    "    \n",
    " hypermodel = LSTM_model(n_input, n_features)   \n",
    "\n",
    " tuner = kt.Hyperband(hypermodel,\n",
    "                     objective = 'val_loss',\n",
    "                     max_epochs = 25,\n",
    "                     factor = 3,\n",
    "                     directory = 'tuners/LSTM_{}'.format(data_type),\n",
    "                     project_name = 'test')\n",
    "\n",
    " stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3, mode=\"min\")\n",
    "\n",
    " tuner.search(train_x, train_y, epochs = 50, validation_split = 0.2, callbacks=[stop_early])\n",
    "\n",
    " # [0] because it return a list of the best to the worst\n",
    " best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    " print(best_hps)\n",
    " model = tuner.hypermodel.build(best_hps)\n",
    " print(model)\n",
    " history = model.fit(train_x, train_y, epochs = 50, validation_split = 0.2, callbacks=[stop_early])\n",
    "\n",
    " #save model\n",
    " model.save('Models/{}.keras'.format(name))\n",
    "\n",
    " with open('hp/{}_hyperparameters.pkl'.format(name), 'wb') as f:\n",
    "     pickle.dump(best_hps.values, f)   \n",
    "  \n",
    " return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c0592-e67a-42d8-b5bc-7a6f14dd0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a forecast for the next day\n",
    "def forecaster(model, his_data, n_input):\n",
    "    \n",
    "\t# flatten data\n",
    "\tdata = array(his_data)\n",
    "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    \n",
    "\t# retrieve last observations for input data\n",
    "\tinput_x = data[-n_input:, :]\n",
    "    \n",
    "\t# reshape into [1, n_input, n]\n",
    "\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "    \n",
    "\t# forecast the next day\n",
    "\tforecast = model.predict(input_x, verbose=0)\n",
    "    \n",
    "\t# we only want the vector forecast\n",
    "\tforecast = forecast[0]\n",
    "\treturn forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c36a6c8-6bdf-44da-99b8-8b9ee10ce449",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input, mean_cons, std_cons, mean_air, std_air, data):\n",
    "    \n",
    " # fit model\n",
    " model, history_epoch = tuner(train, n_input)\n",
    "    \n",
    " # his_data is a list of real data\n",
    " his_data = [x for x in train]\n",
    "    \n",
    " # walk-forward validation over each day\n",
    " predictions = list()\n",
    "\n",
    " start, end = '2022-12-31 12:00:00', '2023-01-01 11:59:00'\n",
    " add_data = data.loc[start:end].copy()\n",
    " add_data.iloc[:,0] = (add_data.iloc[:,0]-mean_cons)/std_cons\n",
    " add_data.iloc[:,1] = (add_data.iloc[:,1]-mean_air)/std_air\n",
    " add_data = array(split(add_data.values, len(add_data)/24)) \n",
    " add_data = add_data[0]\n",
    " his_data.append(add_data)\n",
    "  \n",
    " for i in range(len(test)):\n",
    "\t# predict the next day\n",
    "    forecast = forecaster(model, his_data, n_input)\n",
    "\t# store the forecast\n",
    "    predictions.append(forecast)\n",
    "\t# get real data and add to his_data for predicting the next day\n",
    "    his_data.append(test[i,:])\n",
    "\n",
    "     if (i + 1) % 7 == 0:\n",
    "           train = array(his_data)\n",
    "           train_x, train_y = to_x_y(train, n_input)\n",
    "           # Retrain the model with the updated training data\n",
    "           model.fit(train_x, train_y, epochs = 1)\n",
    "    \n",
    " # re_transform\n",
    " predictions = array(predictions)\n",
    " predictions = (predictions*std_cons)+mean_cons\n",
    " start, end = '2023-01-02 00:00:00', '2023-12-31 23:00:00'\n",
    " actuals = data1.loc[start:end].copy()\n",
    " #actuals =  (actuals*std)+mean   \n",
    " actuals = array(split(actuals.values, len(actuals)/24))\n",
    " actuals = actuals[:, :, 0]\n",
    "\n",
    "\n",
    " # evaluate forecasts \n",
    " score, scores, error_dist = evaluate_forecast(actuals, predictions)\n",
    "    \n",
    " return score, scores, predictions, actuals, error_dist, history_epoch, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5aba60-ff5c-4d4c-8374-ceffe0660d41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run the prediction\n",
    "\n",
    "# splitting into train and test data\n",
    "train, test, mean_cons, std_cons, mean_air, std_air = split_data(data)\n",
    "\n",
    "# evaluating the model and getting the scores\n",
    "score, scores, predictions, actuals, error_dist, history, model = evaluate_model(train, test, n_input, mean_cons, std_cons, mean_air, std_air, data)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "df_error_dist = pd.DataFrame(error_dist)\n",
    "\n",
    "df_error_dist.to_csv('error_dist/{}_error_dist.csv'.format(name) , index=False)\n",
    "\n",
    "\n",
    "# summarize scores\n",
    "performance(name, score, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe90f5-1c94-4675-8b14-4ef6ed95fe77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print history loss\n",
    "print(history.history['loss'])\n",
    "plt.plot(history.history['loss'], label='Training Loss',color=\"red\")\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# set the basic lables\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Model Loss')\n",
    "\n",
    "# tweak the title\n",
    "ttl = ax.title\n",
    "ttl.set_weight('bold')\n",
    "\n",
    "# tweak the axis labels\n",
    "xlab = ax.xaxis.get_label()\n",
    "ylab = ax.yaxis.get_label()\n",
    "xlab.set_style('italic')\n",
    "xlab.set_size(10)\n",
    "ylab.set_style('italic')\n",
    "ylab.set_size(10)\n",
    "\n",
    "# grid on\n",
    "ax.grid('on', linestyle = \"--\", alpha=0.5)\n",
    "\n",
    "# color of plot, just to be sure\n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "# change the color of the top and right spines to opaque gray\n",
    "ax.spines['right'].set_color((.8,.8,.8))\n",
    "ax.spines['top'].set_color((.8,.8,.8))\n",
    "\n",
    "\n",
    "plt.savefig('epochs/{}.png'.format(name))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedbce1f-c78d-4068-b197-02f5d49f1740",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot scores\n",
    "\n",
    "hours = ['00', '01', '02', '03', '04', '05', '06','07', '08', '09', '10', '11', '12', '13','14', '15', '16', '17', '18', '19', '20','21', '22', '23']\n",
    "plt.figure(figsize=(9, 5))\n",
    "\n",
    "boxplot_positions = np.arange(len(hours))\n",
    "# Add boxplots for each column in the error_dist array\n",
    "for col in range(error_dist.shape[1]):\n",
    "    boxplot_values = error_dist[:, col]\n",
    "    plt.boxplot(boxplot_values, positions=[col], widths=0.4, showfliers=False, patch_artist=True, medianprops=dict(color='black'))\n",
    "\n",
    "\n",
    "plt.plot(hours, scores, marker='o', label='lstm', color=\"red\")\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# set the basic lables\n",
    "ax.set_xlabel('Hours')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Average hourly RMSE')\n",
    "\n",
    "# tweak the title\n",
    "ttl = ax.title\n",
    "ttl.set_weight('bold')\n",
    "\n",
    "# tweak the axis labels\n",
    "xlab = ax.xaxis.get_label()\n",
    "ylab = ax.yaxis.get_label()\n",
    "xlab.set_style('italic')\n",
    "xlab.set_size(10)\n",
    "ylab.set_style('italic')\n",
    "ylab.set_size(10)\n",
    "\n",
    "# grid on\n",
    "ax.grid('on', linestyle = \"--\", alpha=0.5)\n",
    "\n",
    "# color of plot, just to be sure\n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "# change the color of the top and right spines to opaque gray\n",
    "ax.spines['right'].set_color((.8,.8,.8))\n",
    "ax.spines['top'].set_color((.8,.8,.8))\n",
    "\n",
    "\n",
    "plt.savefig('scores/{}.png'.format(name))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52643fa8-fa58-42ea-897a-5c4d102485e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pio.renderers.default='browser'\n",
    "pio.templates.default = \"seaborn\"\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "predictions = predictions.flatten()\n",
    "actuals = actuals.flatten()\n",
    "result = pd.DataFrame({'preds': predictions, 'actuals': actuals})\n",
    "\n",
    "start_date = '2023-01-02 00:00:00'\n",
    "end_date = '2023-12-31 23:59:00'\n",
    "date_format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "\n",
    "# Create datetime index\n",
    "datetime_index = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "# Create DataFrame with datetime index, predictions, and actuals\n",
    "resultss = pd.DataFrame({'Datetime': datetime_index, 'Preds': predictions, 'Actuals': actuals})\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "resultss.to_csv('predictions/{}_predictions_actuals.csv'.format(name), index=False)\n",
    "\n",
    "\n",
    "start_datetime = datetime.datetime.strptime(start_date, date_format)\n",
    "end_datetime = datetime.datetime.strptime(end_date, date_format)\n",
    "\n",
    "date_range = pd.date_range(start=start_datetime, end=end_datetime, freq='H')\n",
    "\n",
    "result = result.set_index(date_range)\n",
    "\n",
    "fig = go.Figure([\n",
    "    go.Scatter(\n",
    "        name='Prediction',\n",
    "        x=result.index,\n",
    "        y=result[\"preds\"],\n",
    "        mode='lines',\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        name='Real value',\n",
    "        x=result.index,\n",
    "        y=result[\"actuals\"],\n",
    "        mode='lines',\n",
    "     )\n",
    "])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Real value vs predicted in test data\",\n",
    "    xaxis_title=\"Date time\",\n",
    "    yaxis_title=\"Demand\",\n",
    "    plot_bgcolor='white',\n",
    "    width=800,\n",
    "    height=400,\n",
    "    margin=dict(l=20, r=20, t=35, b=20),\n",
    "    hovermode=\"x\",\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.1,\n",
    "        xanchor=\"left\",\n",
    "        x=0.001\n",
    "    ),\n",
    "    xaxis=dict(linecolor='black',showgrid=True, gridcolor='rgba(0, 0, 0, 0.3)',griddash='dash',mirror=True),\n",
    "    yaxis=dict(linecolor='black',showgrid=True, gridcolor='rgba(0, 0, 0, 0.3)',griddash='dash',mirror=True),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig.write_html('predictions/{}.html'.format(name), auto_open=True)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b8ff1-3e2f-4072-ab0a-4e797b730df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
