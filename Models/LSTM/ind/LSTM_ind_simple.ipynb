{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e228a33-6784-458c-be3f-121e341d90aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_432561/2281816557.py:31: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.engine.hyperparameters import HyperParameters\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import datetime\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# Tensorflow imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import RepeatVector\n",
    "from keras import regularizers\n",
    "from keras.regularizers import L1L2\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b20a3c-bb64-4c72-8f4e-3609f3b279c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "name = \"error\"\n",
    "n_input = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8771baf-3bb8-42b9-80c9-19f84014bd34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_type = \"ind_week\"\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca585e2d-e4df-4692-b402-d7c44ab7ac3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Date: 01/01/2021 00:00\n",
      "Max Date: 31/12/2023 23:00\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/work/Master project/data/data_5_clean_lstm.csv\")\n",
    "\n",
    "df = df\n",
    "df = df.set_index('date')\n",
    "\n",
    "num_cols = ['air_temp','humidity','solar_radiation','dew_point_temp']\n",
    "remainder_cols = ['hour_sin','hour_cos','week_sin','week_cos','month_sin','month_cos','day_of_the_week_sin','day_of_the_week_cos','is_weekend' ]\n",
    "\n",
    "print(\"Min Date:\", df.index.min())\n",
    "print(\"Max Date:\", df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1079bda0-777f-4663-a0e8-aaa451ebaac3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate performance\n",
    "def performance(name, score, scores):\n",
    " use_scores = ', '.join(['%.1f' % s for s in scores])\n",
    " print('%s: [%.3f] %s' % (name, score, use_scores))\n",
    "    \n",
    " # Creating a dictionary of the data\n",
    " data = {'Model': [name],\n",
    "        'Overall RMSE-score': [score]}\n",
    "\n",
    " # Dynamically create columns for scores\n",
    " data.update({f'RMSE Score {i}': [scores[i-1]] for i in range(1, 25)})\n",
    "\n",
    " # Creating a DataFrame from the dictionary\n",
    " df = pd.DataFrame(data)\n",
    "    \n",
    " # Appending the new data to the DataFrame\n",
    " df.to_csv('LSTM_{}_output.csv'.format(data_type), mode='a', index=False, header=False)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cf4e50-d057-449a-803f-f43ef379b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standerdize data\n",
    "def preprocess(X,mean,std,feature):\n",
    "    X.iloc[:,feature] = (X.iloc[:,feature] - mean) / std\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3a2ac0-0aa0-4b2d-b1fa-92e8045b74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index, format='%d/%m/%Y %H:%M')\n",
    "data1 = df.loc['2021-01-01 00:00:00': '2023-12-31 23:00:00'].copy()\n",
    "data1.index = pd.to_datetime(data1.index)\n",
    "data1 = data1.resample(\"H\").sum()\n",
    "\n",
    "# Choose colomns\n",
    "data = data1[[\"electricity_cons\",'air_temp', \"hour_sin\", \"hour_cos\", 'day_of_the_week_sin','day_of_the_week_cos','is_weekend', 'month_cos', 'month_sin','week_sin','week_cos']]\n",
    "\n",
    "# Split into train/test sets\n",
    "def split_data(data):\n",
    "    # split into whole days\n",
    "    train_start, train_end = '2021-01-01 12:00:00', '2022-12-31 11:59:00'\n",
    "    test_start, test_end = '2023-01-01 12:00:00', '2023-12-31 11:59:00'\n",
    "    \n",
    "    train = data.loc[train_start:train_end]\n",
    "    test = data.loc[test_start:test_end]\n",
    "\n",
    "     # standerdize data\n",
    "\n",
    "    cons_train_mean = np.mean(train.iloc[:,0])\n",
    "    cons_train_std = np.std(train.iloc[:,0])\n",
    "    train = preprocess(train,cons_train_mean,cons_train_std,0)\n",
    "    test = preprocess(test,cons_train_mean,cons_train_std,0)\n",
    "\n",
    "    air_train_mean = np.mean(train.iloc[:,1])\n",
    "    air_train_std = np.std(train.iloc[:,1])\n",
    "    train = preprocess(train,air_train_mean,air_train_std,1)\n",
    "    test = preprocess(test,air_train_mean,air_train_std,1)\n",
    "\n",
    "    # hum_train_mean = np.mean(train.iloc[:,2])\n",
    "    # hum_train_std = np.std(train.iloc[:,2])\n",
    "    # train = preprocess(train,hum_train_mean,hum_train_std,2)\n",
    "    # test = preprocess(test,hum_train_mean,hum_train_std,2)\n",
    "\n",
    "    # rad_train_mean = np.mean(train.iloc[:,3])\n",
    "    # rad_train_std = np.std(train.iloc[:,3])\n",
    "    # train = preprocess(train,rad_train_mean,rad_train_std,3)\n",
    "    # test = preprocess(test,rad_train_mean,rad_train_std,3)\n",
    "\n",
    "    # temp_train_mean = np.mean(train.iloc[:,4])\n",
    "    # temp_train_std = np.std(train.iloc[:,4])\n",
    "    # train = preprocess(train,temp_train_mean,temp_train_std,4)\n",
    "    # test = preprocess(test,temp_train_mean,temp_train_std,4)\n",
    "   \n",
    "    \n",
    "    \n",
    "    # restructure into windows of daily data\n",
    "    train = array(split(train.values, len(train)/24))\n",
    "    test = array(split(test.values, len(test)/24))\n",
    "\n",
    "    return train, test, cons_train_mean, cons_train_std,  air_train_mean,  air_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfbb73a7-854e-46ab-b6fa-245974b4bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more daily forecasts against expected values\n",
    "def evaluate_forecast(actual, predicted):\n",
    "    scores = list()\n",
    "    \n",
    "\t# calculate an RMSE score for each hour\n",
    "    for i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "\t\t# store (changede to mse since it otherwise would not make sense on the plot)\n",
    "        scores.append(rmse)\n",
    "    \n",
    "\t# calculate overall RMSE\n",
    "    sum = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            sum += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(sum / (actual.shape[0] * actual.shape[1]))\n",
    "    \n",
    "    # calculate error distribution\n",
    "    error_dist = np.zeros_like(actual, dtype=float)\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            squared_error = (actual[row, col] - predicted[row, col])**2\n",
    "            error_dist[row, col] = sqrt(squared_error)\n",
    "    return score, scores, error_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f1c2ec8-9f31-468f-8f50-aa487cbe2ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert history into inputs and outputs\n",
    "def to_x_y(train, n_input, n_out=24):\n",
    "    # flatten data\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_start = in_end + 12\n",
    "        out_end = out_start + n_out\n",
    "\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            X.append(data[in_start:in_end, :])\n",
    "            y.append(data[out_start:out_end, 0])\n",
    "\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "\n",
    "    return array(X), array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a27cd3f-5b19-4685-9986-0ce965589b72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM_model(HyperModel):\n",
    "    \n",
    "    def __init__(self, n_input, n_features):\n",
    "        self.n_input = n_input\n",
    "        self.n_features = n_features\n",
    "\n",
    "    def build(self, hp):\n",
    "     # define model\n",
    "     model = tf.keras.Sequential()\n",
    "     activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "     layer_1 = hp.Choice('layer_1', values=[2, 4, 8, 16, 32, 64, 128, 256, 512])\n",
    "     layer_2 = hp.Choice('layer_2', values=[2, 4, 8, 16, 32, 64, 128, 256, 512])\n",
    "     learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "    \n",
    "     model.add(LSTM(units = layer_1, activation=activation, input_shape=(self.n_input, self.n_features)))\n",
    "     model.add(Dense(units = layer_2, activation=activation, input_shape=(self.n_input, self.n_features)))\n",
    "     if hp.Boolean(\"dropout\"):\n",
    "         model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.1)))\n",
    "     model.add(Dense(24))\n",
    "     model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "     return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [8, 16, 32, 64]),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "947e80a9-785c-4969-989d-1b8edb6c3aea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tuner(train, n_input):\n",
    "\n",
    " # prepare data\n",
    " train_x, train_y = to_x_y(train, n_input)\n",
    "    \n",
    " n_features = train_x.shape[2]\n",
    "    \n",
    " hypermodel = LSTM_model(n_input, n_features)   \n",
    "\n",
    " tuner = kt.Hyperband(hypermodel,\n",
    "                     objective = 'val_loss',\n",
    "                     max_epochs = 25,\n",
    "                     factor = 3,\n",
    "                     directory = 'tuners/LSTM_simple_{}'.format(data_type),\n",
    "                     project_name = 'test')\n",
    "\n",
    " stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3, mode=\"min\")\n",
    "\n",
    " tuner.search(train_x, train_y, epochs = 50, validation_split = 0.2, callbacks=[stop_early])\n",
    "\n",
    " # [0] because it return a list of the best to the worst\n",
    " best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    " print(best_hps)\n",
    " model = tuner.hypermodel.build(best_hps)\n",
    " print(model)\n",
    " history = model.fit(train_x, train_y, epochs = 50, validation_split = 0.2, callbacks=[stop_early])\n",
    "\n",
    " #save model\n",
    " model.save('Models/{}.keras'.format(name))\n",
    "\n",
    " with open('hp/{}_hyperparameters.pkl'.format(name), 'wb') as f:\n",
    "     pickle.dump(best_hps.values, f)   \n",
    "  \n",
    " return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac9c0592-e67a-42d8-b5bc-7a6f14dd0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a forecast for the next day\n",
    "def forecaster(model, his_data, n_input):\n",
    "    \n",
    "\t# flatten data\n",
    "\tdata = array(his_data)\n",
    "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    \n",
    "\t# retrieve last observations for input data\n",
    "\tinput_x = data[-n_input:, :]\n",
    "    \n",
    "\t# reshape into [1, n_input, n]\n",
    "\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "    \n",
    "\t# forecast the next day\n",
    "\tforecast = model.predict(input_x, verbose=0)\n",
    "    \n",
    "\t# we only want the vector forecast\n",
    "\tforecast = forecast[0]\n",
    "\treturn forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c36a6c8-6bdf-44da-99b8-8b9ee10ce449",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input, mean_cons, std_cons, mean_air, std_air, data):\n",
    "    \n",
    " # fit model\n",
    " model, history_epoch = tuner(train, n_input)\n",
    "    \n",
    " # his_data is a list of real data\n",
    " his_data = [x for x in train]\n",
    "    \n",
    " # walk-forward validation over each day\n",
    " predictions = list()\n",
    "\n",
    " start, end = '2022-12-31 12:00:00', '2023-01-01 11:59:00'\n",
    " add_data = data.loc[start:end].copy()\n",
    " add_data.iloc[:,0] = (add_data.iloc[:,0]-mean_cons)/std_cons\n",
    " add_data.iloc[:,1] = (add_data.iloc[:,1]-mean_air)/std_air\n",
    " add_data = array(split(add_data.values, len(add_data)/24)) \n",
    " add_data = add_data[0]\n",
    " his_data.append(add_data)\n",
    "  \n",
    " for i in range(len(test)):\n",
    "\t# predict the next day\n",
    "    forecast = forecaster(model, his_data, n_input)\n",
    "\t# store the forecast\n",
    "    predictions.append(forecast)\n",
    "\t# get real data and add to his_data for predicting the next day\n",
    "    his_data.append(test[i,:])\n",
    "\n",
    "    # if (i + 1) % 7 == 0:\n",
    "    #      train = array(his_data)\n",
    "    #      train_x, train_y = to_x_y(train, n_input)\n",
    "    #      # Retrain the model with the updated training data\n",
    "    #      model.fit(train_x, train_y, epochs = 1)\n",
    "    \n",
    " # re_transform\n",
    " predictions = array(predictions)\n",
    " predictions = (predictions*std_cons)+mean_cons\n",
    " start, end = '2023-01-02 00:00:00', '2023-12-31 23:00:00'\n",
    " actuals = data1.loc[start:end].copy()\n",
    " #actuals =  (actuals*std)+mean   \n",
    " actuals = array(split(actuals.values, len(actuals)/24))\n",
    " actuals = actuals[:, :, 0]\n",
    "\n",
    "\n",
    " # evaluate forecasts \n",
    " score, scores, error_dist = evaluate_forecast(actuals, predictions)\n",
    "    \n",
    " return score, scores, predictions, actuals, error_dist, history_epoch, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df5aba60-ff5c-4d4c-8374-ceffe0660d41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 Complete [00h 00m 23s]\n",
      "val_loss: 0.8306499719619751\n",
      "\n",
      "Best val_loss So Far: 0.23092781007289886\n",
      "Total elapsed time: 00h 39m 50s\n",
      "\n",
      "Search: Running Trial #22\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "tanh              |relu              |activation\n",
      "512               |256               |layer_1\n",
      "128               |512               |layer_2\n",
      "1e-05             |0.0001            |learning_rate\n",
      "False             |True              |dropout\n",
      "16                |8                 |batch_size\n",
      "0.1               |0                 |Dropout_rate\n",
      "9                 |9                 |tuner/epochs\n",
      "0                 |3                 |tuner/initial_epoch\n",
      "1                 |2                 |tuner/bracket\n",
      "0                 |1                 |tuner/round\n",
      "\n",
      "Epoch 1/9\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 43ms/step - loss: 0.7819 - val_loss: 0.3432\n",
      "Epoch 2/9\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 43ms/step - loss: 0.2945 - val_loss: 0.2845\n",
      "Epoch 3/9\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - loss: 0.2576 - val_loss: 0.2710\n",
      "Epoch 4/9\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 43ms/step - loss: 0.2449 - val_loss: 0.2682\n",
      "Epoch 5/9\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - loss: 0.2345 - val_loss: 0.2620\n",
      "Epoch 6/9\n",
      "\u001b[1m222/872\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - loss: 0.2279"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m train, test, mean, std \u001b[38;5;241m=\u001b[39m split_data(data)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# evaluating the model and getting the scores\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m score, scores, predictions, actuals, error_dist, history, model \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     12\u001b[0m df_error_dist \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(error_dist)\n",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(train, test, n_input, mean, std, data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(train, test, n_input, mean, std, data):\n\u001b[1;32m      3\u001b[0m     \n\u001b[1;32m      4\u001b[0m  \u001b[38;5;66;03m# fit model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m  model, history_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m  \u001b[38;5;66;03m# his_data is a list of real data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m  his_data \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m train]\n",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m, in \u001b[0;36mtuner\u001b[0;34m(train, n_input)\u001b[0m\n\u001b[1;32m     10\u001b[0m tuner \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mHyperband(hypermodel,\n\u001b[1;32m     11\u001b[0m                     objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m                     max_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m     13\u001b[0m                     factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     14\u001b[0m                     directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdir_LSTM_1212\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m                     project_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m stop_early \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstop_early\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# [0] because it return a list of the best to the worst\u001b[39;00m\n\u001b[1;32m     22\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/src/tuners/hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mLSTM_model.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:329\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    328\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 329\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    331\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run the prediction\n",
    "\n",
    "# splitting into train and test data\n",
    "train, test, mean_cons, std_cons, mean_air, std_air = split_data(data)\n",
    "\n",
    "# evaluating the model and getting the scores\n",
    "score, scores, predictions, actuals, error_dist, history, model = evaluate_model(train, test, n_input, mean_cons, std_cons, mean_air, std_air, data)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "df_error_dist = pd.DataFrame(error_dist)\n",
    "\n",
    "df_error_dist.to_csv('error_dist/{}_error_dist.csv'.format(name) , index=False)\n",
    "\n",
    "\n",
    "# summarize scores\n",
    "performance(name, score, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe90f5-1c94-4675-8b14-4ef6ed95fe77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print history loss\n",
    "print(history.history['loss'])\n",
    "plt.plot(history.history['loss'], label='Training Loss',color=\"red\")\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# set the basic lables\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Model Loss')\n",
    "\n",
    "# tweak the title\n",
    "ttl = ax.title\n",
    "ttl.set_weight('bold')\n",
    "\n",
    "# tweak the axis labels\n",
    "xlab = ax.xaxis.get_label()\n",
    "ylab = ax.yaxis.get_label()\n",
    "xlab.set_style('italic')\n",
    "xlab.set_size(10)\n",
    "ylab.set_style('italic')\n",
    "ylab.set_size(10)\n",
    "\n",
    "# grid on\n",
    "ax.grid('on', linestyle = \"--\", alpha=0.5)\n",
    "\n",
    "# color of plot, just to be sure\n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "# change the color of the top and right spines to opaque gray\n",
    "ax.spines['right'].set_color((.8,.8,.8))\n",
    "ax.spines['top'].set_color((.8,.8,.8))\n",
    "\n",
    "\n",
    "plt.savefig('epochs/{}.png'.format(name))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedbce1f-c78d-4068-b197-02f5d49f1740",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot scores\n",
    "\n",
    "hours = ['00', '01', '02', '03', '04', '05', '06','07', '08', '09', '10', '11', '12', '13','14', '15', '16', '17', '18', '19', '20','21', '22', '23']\n",
    "plt.figure(figsize=(9, 5))\n",
    "\n",
    "boxplot_positions = np.arange(len(hours))\n",
    "# Add boxplots for each column in the error_dist array\n",
    "for col in range(error_dist.shape[1]):\n",
    "    boxplot_values = error_dist[:, col]\n",
    "    plt.boxplot(boxplot_values, positions=[col], widths=0.4, showfliers=False, patch_artist=True, medianprops=dict(color='black'))\n",
    "\n",
    "\n",
    "plt.plot(hours, scores, marker='o', label='lstm', color=\"red\")\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# set the basic lables\n",
    "ax.set_xlabel('Hours')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Average hourly RMSE')\n",
    "\n",
    "# tweak the title\n",
    "ttl = ax.title\n",
    "ttl.set_weight('bold')\n",
    "\n",
    "# tweak the axis labels\n",
    "xlab = ax.xaxis.get_label()\n",
    "ylab = ax.yaxis.get_label()\n",
    "xlab.set_style('italic')\n",
    "xlab.set_size(10)\n",
    "ylab.set_style('italic')\n",
    "ylab.set_size(10)\n",
    "\n",
    "# grid on\n",
    "ax.grid('on', linestyle = \"--\", alpha=0.5)\n",
    "\n",
    "# color of plot, just to be sure\n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "# change the color of the top and right spines to opaque gray\n",
    "ax.spines['right'].set_color((.8,.8,.8))\n",
    "ax.spines['top'].set_color((.8,.8,.8))\n",
    "\n",
    "\n",
    "plt.savefig('scores/{}.png'.format(name))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52643fa8-fa58-42ea-897a-5c4d102485e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pio.renderers.default='browser'\n",
    "pio.templates.default = \"seaborn\"\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "predictions = predictions.flatten()\n",
    "actuals = actuals.flatten()\n",
    "result = pd.DataFrame({'preds': predictions, 'actuals': actuals})\n",
    "\n",
    "start_date = '2023-01-02 00:00:00'\n",
    "end_date = '2023-12-31 23:59:00'\n",
    "date_format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "\n",
    "# Create datetime index\n",
    "datetime_index = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "# Create DataFrame with datetime index, predictions, and actuals\n",
    "resultss = pd.DataFrame({'Datetime': datetime_index, 'Preds': predictions, 'Actuals': actuals})\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "resultss.to_csv('predictions/{}_predictions_actuals.csv'.format(name), index=False)\n",
    "\n",
    "\n",
    "start_datetime = datetime.datetime.strptime(start_date, date_format)\n",
    "end_datetime = datetime.datetime.strptime(end_date, date_format)\n",
    "\n",
    "date_range = pd.date_range(start=start_datetime, end=end_datetime, freq='H')\n",
    "\n",
    "result = result.set_index(date_range)\n",
    "\n",
    "fig = go.Figure([\n",
    "    go.Scatter(\n",
    "        name='Prediction',\n",
    "        x=result.index,\n",
    "        y=result[\"preds\"],\n",
    "        mode='lines',\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        name='Real value',\n",
    "        x=result.index,\n",
    "        y=result[\"actuals\"],\n",
    "        mode='lines',\n",
    "     )\n",
    "])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Real value vs predicted in test data\",\n",
    "    xaxis_title=\"Date time\",\n",
    "    yaxis_title=\"Demand\",\n",
    "    plot_bgcolor='white',\n",
    "    width=800,\n",
    "    height=400,\n",
    "    margin=dict(l=20, r=20, t=35, b=20),\n",
    "    hovermode=\"x\",\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.1,\n",
    "        xanchor=\"left\",\n",
    "        x=0.001\n",
    "    ),\n",
    "    xaxis=dict(linecolor='black',showgrid=True, gridcolor='rgba(0, 0, 0, 0.3)',griddash='dash',mirror=True),\n",
    "    yaxis=dict(linecolor='black',showgrid=True, gridcolor='rgba(0, 0, 0, 0.3)',griddash='dash',mirror=True),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig.write_html('predictions/{}.html'.format(name), auto_open=True)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b8ff1-3e2f-4072-ab0a-4e797b730df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
