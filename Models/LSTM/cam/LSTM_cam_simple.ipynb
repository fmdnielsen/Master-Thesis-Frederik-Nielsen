{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e228a33-6784-458c-be3f-121e341d90aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1004577/2281816557.py:31: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.engine.hyperparameters import HyperParameters\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import datetime\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# Tensorflow imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import RepeatVector\n",
    "from keras import regularizers\n",
    "from keras.regularizers import L1L2\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b20a3c-bb64-4c72-8f4e-3609f3b279c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "name = \"error\"\n",
    "n_input = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8771baf-3bb8-42b9-80c9-19f84014bd34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_type = \"cam_week\"\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca585e2d-e4df-4692-b402-d7c44ab7ac3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Date: 01/01/2021 00:00\n",
      "Max Date: 31/12/2023 23:00\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/work/Master project/data/data_4_clean_lstm.csv\")\n",
    "\n",
    "df = df\n",
    "df = df.set_index('date')\n",
    "\n",
    "num_cols = ['air_temp','humidity','solar_radiation','dew_point_temp']\n",
    "remainder_cols = ['hour_sin','hour_cos','week_sin','week_cos','month_sin','month_cos','day_of_the_week_sin','day_of_the_week_cos','is_weekend' ]\n",
    "\n",
    "print(\"Min Date:\", df.index.min())\n",
    "print(\"Max Date:\", df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1079bda0-777f-4663-a0e8-aaa451ebaac3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate performance\n",
    "def performance(name, score, scores):\n",
    " use_scores = ', '.join(['%.1f' % s for s in scores])\n",
    " print('%s: [%.3f] %s' % (name, score, use_scores))\n",
    "    \n",
    " # Creating a dictionary of the data\n",
    " data = {'Model': [name],\n",
    "        'Overall RMSE-score': [score]}\n",
    "\n",
    " # Dynamically create columns for scores\n",
    " data.update({f'RMSE Score {i}': [scores[i-1]] for i in range(1, 25)})\n",
    "\n",
    " # Creating a DataFrame from the dictionary\n",
    " df = pd.DataFrame(data)\n",
    "    \n",
    " # Appending the new data to the DataFrame\n",
    " df.to_csv('LSTM_{}_output.csv'.format(data_type), mode='a', index=False, header=False)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cf4e50-d057-449a-803f-f43ef379b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standerdize data\n",
    "def preprocess(X,mean,std,feature):\n",
    "    X.iloc[:,feature] = (X.iloc[:,feature] - mean) / std\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3a2ac0-0aa0-4b2d-b1fa-92e8045b74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index, format='%Y-%m-%d %H:%M:%S')\n",
    "data1 = df.loc['2018-01-01 00:00:00': '2020-12-31 23:00:00'].copy()\n",
    "data1.index = pd.to_datetime(data1.index)\n",
    "data1 = data1.resample(\"H\").sum()\n",
    "\n",
    "# Choose colomns\n",
    "data = data1[[\"electricity_cons\",'air_temp', \"hour_sin\", \"hour_cos\", 'day_of_the_week_sin','day_of_the_week_cos','is_weekend', 'month_cos', 'month_sin','week_sin','week_cos']]\n",
    "\n",
    "# Split into train/test sets\n",
    "def split_data(data):\n",
    "    # split into whole days\n",
    "    train_start, train_end = '2019-01-01 12:00:00', '2019-12-31 11:59:00'\n",
    "    test_start, test_end = '2020-01-01 12:00:00', '2020-12-31 11:59:00'\n",
    "    \n",
    "    train = data.loc[train_start:train_end]\n",
    "    test = data.loc[test_start:test_end]\n",
    "\n",
    "     # standerdize data\n",
    "\n",
    "    cons_train_mean = np.mean(train.iloc[:,0])\n",
    "    cons_train_std = np.std(train.iloc[:,0])\n",
    "    train = preprocess(train,cons_train_mean,cons_train_std,0)\n",
    "    test = preprocess(test,cons_train_mean,cons_train_std,0)\n",
    "\n",
    "    air_train_mean = np.mean(train.iloc[:,1])\n",
    "    air_train_std = np.std(train.iloc[:,1])\n",
    "    train = preprocess(train,air_train_mean,air_train_std,1)\n",
    "    test = preprocess(test,air_train_mean,air_train_std,1)\n",
    "\n",
    "    # hum_train_mean = np.mean(train.iloc[:,2])\n",
    "    # hum_train_std = np.std(train.iloc[:,2])\n",
    "    # train = preprocess(train,hum_train_mean,hum_train_std,2)\n",
    "    # test = preprocess(test,hum_train_mean,hum_train_std,2)\n",
    "\n",
    "    # rad_train_mean = np.mean(train.iloc[:,3])\n",
    "    # rad_train_std = np.std(train.iloc[:,3])\n",
    "    # train = preprocess(train,rad_train_mean,rad_train_std,3)\n",
    "    # test = preprocess(test,rad_train_mean,rad_train_std,3)\n",
    "\n",
    "    # temp_train_mean = np.mean(train.iloc[:,4])\n",
    "    # temp_train_std = np.std(train.iloc[:,4])\n",
    "    # train = preprocess(train,temp_train_mean,temp_train_std,4)\n",
    "    # test = preprocess(test,temp_train_mean,temp_train_std,4)\n",
    "   \n",
    "    \n",
    "    \n",
    "    # restructure into windows of daily data\n",
    "    train = array(split(train.values, len(train)/24))\n",
    "    test = array(split(test.values, len(test)/24))\n",
    "\n",
    "    return train, test, cons_train_mean, cons_train_std,  air_train_mean,  air_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfbb73a7-854e-46ab-b6fa-245974b4bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more daily forecasts against expected values\n",
    "def evaluate_forecast(actual, predicted):\n",
    "    scores = list()\n",
    "    \n",
    "\t# calculate an RMSE score for each hour\n",
    "    for i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "\t\t# store (changede to mse since it otherwise would not make sense on the plot)\n",
    "        scores.append(rmse)\n",
    "    \n",
    "\t# calculate overall RMSE\n",
    "    sum = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            sum += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(sum / (actual.shape[0] * actual.shape[1]))\n",
    "    \n",
    "    # calculate error distribution\n",
    "    error_dist = np.zeros_like(actual, dtype=float)\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            squared_error = (actual[row, col] - predicted[row, col])**2\n",
    "            error_dist[row, col] = sqrt(squared_error)\n",
    "    return score, scores, error_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f1c2ec8-9f31-468f-8f50-aa487cbe2ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert history into inputs and outputs\n",
    "def to_x_y(train, n_input, n_out=24):\n",
    "    # flatten data\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_start = in_end + 12\n",
    "        out_end = out_start + n_out\n",
    "\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            X.append(data[in_start:in_end, :])\n",
    "            y.append(data[out_start:out_end, 0])\n",
    "\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "\n",
    "    return array(X), array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a27cd3f-5b19-4685-9986-0ce965589b72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM_model(HyperModel):\n",
    "    \n",
    "    def __init__(self, n_input, n_features):\n",
    "        self.n_input = n_input\n",
    "        self.n_features = n_features\n",
    "\n",
    "    def build(self, hp):\n",
    "     # define model\n",
    "     model = tf.keras.Sequential()\n",
    "     activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "     layer_1 = hp.Choice('layer_1', values=[2, 4, 8, 16, 32, 64, 128, 256, 512])\n",
    "     layer_2 = hp.Choice('layer_2', values=[2, 4, 8, 16, 32, 64, 128, 256, 512])\n",
    "     learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "    \n",
    "     model.add(LSTM(units = layer_1, activation=activation, input_shape=(self.n_input, self.n_features)))\n",
    "     model.add(Dense(units = layer_2, activation=activation, input_shape=(self.n_input, self.n_features)))\n",
    "     if hp.Boolean(\"dropout\"):\n",
    "         model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.1)))\n",
    "     model.add(Dense(24))\n",
    "     model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "     return model\n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [8, 16, 32, 64]),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "947e80a9-785c-4969-989d-1b8edb6c3aea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tuner(train, n_input):\n",
    "\n",
    " # prepare data\n",
    " train_x, train_y = to_x_y(train, n_input)\n",
    "    \n",
    " n_features = train_x.shape[2]\n",
    "    \n",
    " hypermodel = LSTM_model(n_input, n_features)   \n",
    "\n",
    " tuner = kt.Hyperband(hypermodel,\n",
    "                     objective = 'val_loss',\n",
    "                     max_epochs = 25,\n",
    "                     factor = 3,\n",
    "                     directory = 'tuners/LSTM_simple_{}_real'.format(data_type),\n",
    "                     project_name = 'test')\n",
    "\n",
    " stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3, mode=\"min\")\n",
    "\n",
    " tuner.search(train_x, train_y, epochs = 50, validation_split = 0.2, callbacks=[stop_early])\n",
    "\n",
    " # [0] because it return a list of the best to the worst\n",
    " best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    " print(best_hps)\n",
    " model = tuner.hypermodel.build(best_hps)\n",
    " print(model)\n",
    " history = model.fit(train_x, train_y, epochs = 50, validation_split = 0.2, callbacks=[stop_early])\n",
    "\n",
    " #save model\n",
    " model.save('Models/{}.keras'.format(name))\n",
    "\n",
    " with open('hp/{}_hyperparameters.pkl'.format(name), 'wb') as f:\n",
    "     pickle.dump(best_hps.values, f)   \n",
    "  \n",
    " return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac9c0592-e67a-42d8-b5bc-7a6f14dd0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a forecast for the next day\n",
    "def forecaster(model, his_data, n_input):\n",
    "    \n",
    "\t# flatten data\n",
    "\tdata = array(his_data)\n",
    "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    \n",
    "\t# retrieve last observations for input data\n",
    "\tinput_x = data[-n_input:, :]\n",
    "    \n",
    "\t# reshape into [1, n_input, n]\n",
    "\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "    \n",
    "\t# forecast the next day\n",
    "\tforecast = model.predict(input_x, verbose=0)\n",
    "    \n",
    "\t# we only want the vector forecast\n",
    "\tforecast = forecast[0]\n",
    "\treturn forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c36a6c8-6bdf-44da-99b8-8b9ee10ce449",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input, mean_cons, std_cons, mean_air, std_air, data):\n",
    "    \n",
    " # fit model\n",
    " model, history_epoch = tuner(train, n_input)\n",
    "    \n",
    " # his_data is a list of real data\n",
    " his_data = [x for x in train]\n",
    "    \n",
    " # walk-forward validation over each day\n",
    " predictions = list()\n",
    "\n",
    " start, end = '2019-12-31 12:00:00', '2020-01-01 11:59:00'\n",
    " add_data = data.loc[start:end].copy()\n",
    " add_data.iloc[:,0] = (add_data.iloc[:,0]-mean_cons)/std_cons\n",
    " add_data.iloc[:,1] = (add_data.iloc[:,1]-mean_air)/std_air\n",
    "\n",
    " print(add_data)\n",
    " add_data = array(split(add_data.values, len(add_data)/24)) \n",
    " add_data = add_data[0]\n",
    " his_data.append(add_data)\n",
    "  \n",
    " for i in range(len(test)):\n",
    "\t# predict the next day\n",
    "    forecast = forecaster(model, his_data, n_input)\n",
    "\t# store the forecast\n",
    "    predictions.append(forecast)\n",
    "\t# get real data and add to his_data for predicting the next day\n",
    "    his_data.append(test[i,:])\n",
    "\n",
    "    if (i + 1) % 7 == 0:\n",
    "         train = array(his_data)\n",
    "         train_x, train_y = to_x_y(train, n_input)\n",
    "         # Retrain the model with the updated training data\n",
    "         model.fit(train_x, train_y, epochs = 1)\n",
    "    \n",
    " # re_transform\n",
    " predictions = array(predictions)\n",
    " predictions = (predictions*std_cons)+mean_cons\n",
    " start, end = '2020-01-02 00:00:00', '2020-12-31 23:00:00'\n",
    " actuals = data1.loc[start:end].copy()\n",
    " #actuals =  (actuals*std)+mean   \n",
    " actuals = array(split(actuals.values, len(actuals)/24))\n",
    " actuals = actuals[:, :, 0]\n",
    "\n",
    "\n",
    " # evaluate forecasts \n",
    " score, scores, error_dist = evaluate_forecast(actuals, predictions)\n",
    "    \n",
    " return score, scores, predictions, actuals, error_dist, history_epoch, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df5aba60-ff5c-4d4c-8374-ceffe0660d41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuners/LSTM_simple_res_real/test/tuner0.json\n",
      "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7ef93638d000>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sequential name=sequential, built=True>\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m436/436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 64ms/step - loss: 0.4754 - val_loss: 0.0988\n",
      "Epoch 2/50\n",
      "\u001b[1m436/436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 62ms/step - loss: 0.1015 - val_loss: 0.1097\n",
      "Epoch 3/50\n",
      "\u001b[1m436/436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 66ms/step - loss: 0.0669 - val_loss: 0.1025\n",
      "Epoch 4/50\n",
      "\u001b[1m436/436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 65ms/step - loss: 0.0564 - val_loss: 0.0995\n",
      "                     electricity_cons  air_temp  humidity  solar_radiation  \\\n",
      "date                                                                         \n",
      "2022-12-31 12:00:00          0.750005 -0.150922  1.007925        -0.483829   \n",
      "2022-12-31 13:00:00          0.782327 -0.135569  1.175631        -0.557623   \n",
      "2022-12-31 14:00:00          0.796333  0.064014  1.111129        -0.590230   \n",
      "2022-12-31 15:00:00          0.843737  0.191952  0.762816        -0.612540   \n",
      "2022-12-31 16:00:00          1.211663  0.176599  0.698314        -0.613398   \n",
      "2022-12-31 17:00:00          1.402898  0.066573  0.943423        -0.613398   \n",
      "2022-12-31 18:00:00          0.944472  0.005162  1.046627        -0.613398   \n",
      "2022-12-31 19:00:00          0.714452 -0.033219  1.162731        -0.613398   \n",
      "2022-12-31 20:00:00          0.477967 -0.005073  1.149830        -0.613398   \n",
      "2022-12-31 21:00:00          0.296967  0.061455  1.111129        -0.613398   \n",
      "2022-12-31 22:00:00          0.121354  0.156129  1.020826        -0.613398   \n",
      "2022-12-31 23:00:00          0.002842  0.212422  1.046627        -0.613398   \n",
      "2023-01-01 00:00:00          0.025467  0.214981  0.762816        -0.613398   \n",
      "2023-01-01 01:00:00         -0.020861  0.227775  0.466106        -0.613398   \n",
      "2023-01-01 02:00:00         -0.080117  0.232892  0.491907        -0.613398   \n",
      "2023-01-01 03:00:00         -0.174926  0.202187  0.569310        -0.613398   \n",
      "2023-01-01 04:00:00         -0.232027  0.209863  0.414504        -0.613398   \n",
      "2023-01-01 05:00:00         -0.254114  0.181717  0.569310        -0.613398   \n",
      "2023-01-01 06:00:00         -0.245495  0.158688  0.608011        -0.613398   \n",
      "2023-01-01 07:00:00         -0.167923  0.186834  0.427404        -0.613398   \n",
      "2023-01-01 08:00:00         -0.002007  0.130542  0.324201        -0.585082   \n",
      "2023-01-01 09:00:00          0.268955  0.122865  0.233898        -0.502706   \n",
      "2023-01-01 10:00:00          0.388005  0.071690  0.117793        -0.329374   \n",
      "2023-01-01 11:00:00          0.515136  0.038426  0.027490        -0.337955   \n",
      "\n",
      "                         hour_sin      hour_cos  day_of_the_week_sin  \\\n",
      "date                                                                   \n",
      "2022-12-31 12:00:00  1.220000e-16 -1.000000e+00            -0.974928   \n",
      "2022-12-31 13:00:00 -2.588190e-01 -9.659258e-01            -0.974928   \n",
      "2022-12-31 14:00:00 -5.000000e-01 -8.660254e-01            -0.974928   \n",
      "2022-12-31 15:00:00 -7.071068e-01 -7.071068e-01            -0.974928   \n",
      "2022-12-31 16:00:00 -8.660254e-01 -5.000000e-01            -0.974928   \n",
      "2022-12-31 17:00:00 -9.659258e-01 -2.588190e-01            -0.974928   \n",
      "2022-12-31 18:00:00 -1.000000e+00 -1.840000e-16            -0.974928   \n",
      "2022-12-31 19:00:00 -9.659258e-01  2.588190e-01            -0.974928   \n",
      "2022-12-31 20:00:00 -8.660254e-01  5.000000e-01            -0.974928   \n",
      "2022-12-31 21:00:00 -7.071068e-01  7.071068e-01            -0.974928   \n",
      "2022-12-31 22:00:00 -5.000000e-01  8.660254e-01            -0.974928   \n",
      "2022-12-31 23:00:00 -2.588190e-01  9.659258e-01            -0.974928   \n",
      "2023-01-01 00:00:00  0.000000e+00  1.000000e+00            -0.781831   \n",
      "2023-01-01 01:00:00  2.588190e-01  9.659258e-01            -0.781831   \n",
      "2023-01-01 02:00:00  5.000000e-01  8.660254e-01            -0.781831   \n",
      "2023-01-01 03:00:00  7.071068e-01  7.071068e-01            -0.781831   \n",
      "2023-01-01 04:00:00  8.660254e-01  5.000000e-01            -0.781831   \n",
      "2023-01-01 05:00:00  9.659258e-01  2.588190e-01            -0.781831   \n",
      "2023-01-01 06:00:00  1.000000e+00  6.120000e-17            -0.781831   \n",
      "2023-01-01 07:00:00  9.659258e-01 -2.588190e-01            -0.781831   \n",
      "2023-01-01 08:00:00  8.660254e-01 -5.000000e-01            -0.781831   \n",
      "2023-01-01 09:00:00  7.071068e-01 -7.071068e-01            -0.781831   \n",
      "2023-01-01 10:00:00  5.000000e-01 -8.660254e-01            -0.781831   \n",
      "2023-01-01 11:00:00  2.588190e-01 -9.659258e-01            -0.781831   \n",
      "\n",
      "                     day_of_the_week_cos  is_weekend  month_cos     month_sin  \\\n",
      "date                                                                            \n",
      "2022-12-31 12:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2022-12-31 13:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2022-12-31 14:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2022-12-31 15:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2022-12-31 16:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2022-12-31 17:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2022-12-31 18:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2022-12-31 19:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2022-12-31 20:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2022-12-31 21:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2022-12-31 22:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2022-12-31 23:00:00            -0.222521           1   1.000000 -2.450000e-16   \n",
      "2023-01-01 00:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "2023-01-01 01:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "2023-01-01 02:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "2023-01-01 03:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "2023-01-01 04:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "2023-01-01 05:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "2023-01-01 06:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "2023-01-01 07:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "2023-01-01 08:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "2023-01-01 09:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "2023-01-01 10:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "2023-01-01 11:00:00             0.623490           1   0.866025  5.000000e-01   \n",
      "\n",
      "                         week_sin  week_cos  \n",
      "date                                         \n",
      "2022-12-31 12:00:00  6.430000e-16       1.0  \n",
      "2022-12-31 13:00:00  6.430000e-16       1.0  \n",
      "2022-12-31 14:00:00  6.430000e-16       1.0  \n",
      "2022-12-31 15:00:00  6.430000e-16       1.0  \n",
      "2022-12-31 16:00:00  6.430000e-16       1.0  \n",
      "2022-12-31 17:00:00  6.430000e-16       1.0  \n",
      "2022-12-31 18:00:00  6.430000e-16       1.0  \n",
      "2022-12-31 19:00:00  6.430000e-16       1.0  \n",
      "2022-12-31 20:00:00  6.430000e-16       1.0  \n",
      "2022-12-31 21:00:00  6.430000e-16       1.0  \n",
      "2022-12-31 22:00:00  6.430000e-16       1.0  \n",
      "2022-12-31 23:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 00:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 01:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 02:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 03:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 04:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 05:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 06:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 07:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 08:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 09:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 10:00:00  6.430000e-16       1.0  \n",
      "2023-01-01 11:00:00  6.430000e-16       1.0  \n",
      "\u001b[1m551/551\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 60ms/step - loss: 0.0551\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 59ms/step - loss: 0.0500\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 59ms/step - loss: 0.0474\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 59ms/step - loss: 0.0437\n",
      "\u001b[1m572/572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 57ms/step - loss: 0.0421\n",
      "\u001b[1m578/578\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 58ms/step - loss: 0.0391\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 58ms/step - loss: 0.0394\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 64ms/step - loss: 0.0367\n",
      "\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 59ms/step - loss: 0.0356\n",
      "\u001b[1m599/599\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 51ms/step - loss: 0.0329\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 51ms/step - loss: 0.0324\n",
      "\u001b[1m609/609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 58ms/step - loss: 0.0312\n",
      "\u001b[1m614/614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - loss: 0.0287\n",
      "\u001b[1m620/620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - loss: 0.0273\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 55ms/step - loss: 0.0247\n",
      "\u001b[1m630/630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 71ms/step - loss: 0.0232\n",
      "\u001b[1m635/635\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 64ms/step - loss: 0.0223\n",
      "\u001b[1m641/641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 62ms/step - loss: 0.0217\n",
      "\u001b[1m646/646\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 73ms/step - loss: 0.0197\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 71ms/step - loss: 0.0190\n",
      "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 58ms/step - loss: 0.0178\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 58ms/step - loss: 0.0165\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 58ms/step - loss: 0.0158\n",
      "\u001b[1m672/672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 58ms/step - loss: 0.0143\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 58ms/step - loss: 0.0136\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 59ms/step - loss: 0.0128\n",
      "\u001b[1m688/688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 58ms/step - loss: 0.0124\n",
      "\u001b[1m693/693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 58ms/step - loss: 0.0115\n",
      "\u001b[1m698/698\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 57ms/step - loss: 0.0112\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 55ms/step - loss: 0.0106\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 57ms/step - loss: 0.0101\n",
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 58ms/step - loss: 0.0098\n",
      "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 58ms/step - loss: 0.0091\n",
      "\u001b[1m725/725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - loss: 0.0087\n",
      "\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - loss: 0.0088\n",
      "\u001b[1m735/735\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 59ms/step - loss: 0.0080\n",
      "\u001b[1m740/740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 59ms/step - loss: 0.0077\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 59ms/step - loss: 0.0075\n",
      "\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 58ms/step - loss: 0.0072\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 58ms/step - loss: 0.0071\n",
      "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 59ms/step - loss: 0.0070\n",
      "\u001b[1m767/767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 59ms/step - loss: 0.0077\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 59ms/step - loss: 0.0073\n",
      "\u001b[1m777/777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 60ms/step - loss: 0.0074\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 60ms/step - loss: 0.0075\n",
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 60ms/step - loss: 0.0069\n",
      "\u001b[1m793/793\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 60ms/step - loss: 0.0080\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 60ms/step - loss: 0.0088\n",
      "\u001b[1m803/803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 60ms/step - loss: 0.0073\n",
      "\u001b[1m809/809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 60ms/step - loss: 0.0080\n",
      "\u001b[1m814/814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 60ms/step - loss: 0.0075\n",
      "\u001b[1m819/819\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 60ms/step - loss: 0.0070\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m train, test, mean_cons, std_cons, mean_air, std_air, mean_hum, std_hum, mean_rad, std_rad \u001b[38;5;241m=\u001b[39m split_data(data)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# evaluating the model and getting the scores\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m score, scores, predictions, actuals, error_dist, history, model \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_cons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_cons\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmean_air\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_air\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmean_hum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_hum\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmean_rad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_rad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     12\u001b[0m df_error_dist \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(error_dist)\n",
      "Cell \u001b[0;32mIn[13], line 40\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(train, test, n_input, mean_cons, std_cons, mean_air, std_air, mean_hum, std_hum, mean_rad, std_rad, data)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# re_transform\u001b[39;00m\n\u001b[1;32m     39\u001b[0m predictions \u001b[38;5;241m=\u001b[39m array(predictions)\n\u001b[0;32m---> 40\u001b[0m predictions \u001b[38;5;241m=\u001b[39m (predictions\u001b[38;5;241m*\u001b[39m\u001b[43mstd\u001b[49m)\u001b[38;5;241m+\u001b[39mmean\n\u001b[1;32m     41\u001b[0m start, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-01-02 00:00:00\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-12-31 23:00:00\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     42\u001b[0m actuals \u001b[38;5;241m=\u001b[39m data1\u001b[38;5;241m.\u001b[39mloc[start:end]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'std' is not defined"
     ]
    }
   ],
   "source": [
    "# run the prediction\n",
    "\n",
    "# splitting into train and test data\n",
    "train, test, mean_cons, std_cons, mean_air, std_air = split_data(data)\n",
    "\n",
    "# evaluating the model and getting the scores\n",
    "score, scores, predictions, actuals, error_dist, history, model = evaluate_model(train, test, n_input, mean_cons, std_cons, mean_air, std_air, data)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "df_error_dist = pd.DataFrame(error_dist)\n",
    "\n",
    "df_error_dist.to_csv('error_dist/{}_error_dist.csv'.format(name) , index=False)\n",
    "\n",
    "\n",
    "# summarize scores\n",
    "performance(name, score, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe90f5-1c94-4675-8b14-4ef6ed95fe77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print history loss\n",
    "print(history.history['loss'])\n",
    "plt.plot(history.history['loss'], label='Training Loss',color=\"red\")\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# set the basic lables\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Model Loss')\n",
    "\n",
    "# tweak the title\n",
    "ttl = ax.title\n",
    "ttl.set_weight('bold')\n",
    "\n",
    "# tweak the axis labels\n",
    "xlab = ax.xaxis.get_label()\n",
    "ylab = ax.yaxis.get_label()\n",
    "xlab.set_style('italic')\n",
    "xlab.set_size(10)\n",
    "ylab.set_style('italic')\n",
    "ylab.set_size(10)\n",
    "\n",
    "# grid on\n",
    "ax.grid('on', linestyle = \"--\", alpha=0.5)\n",
    "\n",
    "# color of plot, just to be sure\n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "# change the color of the top and right spines to opaque gray\n",
    "ax.spines['right'].set_color((.8,.8,.8))\n",
    "ax.spines['top'].set_color((.8,.8,.8))\n",
    "\n",
    "\n",
    "plt.savefig('epochs/{}.png'.format(name))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedbce1f-c78d-4068-b197-02f5d49f1740",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot scores\n",
    "\n",
    "hours = ['00', '01', '02', '03', '04', '05', '06','07', '08', '09', '10', '11', '12', '13','14', '15', '16', '17', '18', '19', '20','21', '22', '23']\n",
    "plt.figure(figsize=(9, 5))\n",
    "\n",
    "boxplot_positions = np.arange(len(hours))\n",
    "# Add boxplots for each column in the error_dist array\n",
    "for col in range(error_dist.shape[1]):\n",
    "    boxplot_values = error_dist[:, col]\n",
    "    plt.boxplot(boxplot_values, positions=[col], widths=0.4, showfliers=False, patch_artist=True, medianprops=dict(color='black'))\n",
    "\n",
    "\n",
    "plt.plot(hours, scores, marker='o', label='lstm', color=\"red\")\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# set the basic lables\n",
    "ax.set_xlabel('Hours')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Average hourly RMSE')\n",
    "\n",
    "# tweak the title\n",
    "ttl = ax.title\n",
    "ttl.set_weight('bold')\n",
    "\n",
    "# tweak the axis labels\n",
    "xlab = ax.xaxis.get_label()\n",
    "ylab = ax.yaxis.get_label()\n",
    "xlab.set_style('italic')\n",
    "xlab.set_size(10)\n",
    "ylab.set_style('italic')\n",
    "ylab.set_size(10)\n",
    "\n",
    "# grid on\n",
    "ax.grid('on', linestyle = \"--\", alpha=0.5)\n",
    "\n",
    "# color of plot, just to be sure\n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "# change the color of the top and right spines to opaque gray\n",
    "ax.spines['right'].set_color((.8,.8,.8))\n",
    "ax.spines['top'].set_color((.8,.8,.8))\n",
    "\n",
    "\n",
    "plt.savefig('scores/{}.png'.format(name))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52643fa8-fa58-42ea-897a-5c4d102485e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pio.renderers.default='browser'\n",
    "pio.templates.default = \"seaborn\"\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "predictions = predictions.flatten()\n",
    "actuals = actuals.flatten()\n",
    "result = pd.DataFrame({'preds': predictions, 'actuals': actuals})\n",
    "\n",
    "start_date = '2020-01-02 00:00:00'\n",
    "end_date = '2020-12-31 23:59:00'\n",
    "date_format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "\n",
    "# Create datetime index\n",
    "datetime_index = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "# Create DataFrame with datetime index, predictions, and actuals\n",
    "resultss = pd.DataFrame({'Datetime': datetime_index, 'Preds': predictions, 'Actuals': actuals})\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "resultss.to_csv('predictions/{}_predictions_actuals.csv'.format(name), index=False)\n",
    "\n",
    "\n",
    "start_datetime = datetime.datetime.strptime(start_date, date_format)\n",
    "end_datetime = datetime.datetime.strptime(end_date, date_format)\n",
    "\n",
    "date_range = pd.date_range(start=start_datetime, end=end_datetime, freq='H')\n",
    "\n",
    "result = result.set_index(date_range)\n",
    "\n",
    "fig = go.Figure([\n",
    "    go.Scatter(\n",
    "        name='Prediction',\n",
    "        x=result.index,\n",
    "        y=result[\"preds\"],\n",
    "        mode='lines',\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        name='Real value',\n",
    "        x=result.index,\n",
    "        y=result[\"actuals\"],\n",
    "        mode='lines',\n",
    "     )\n",
    "])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Real value vs predicted in test data\",\n",
    "    xaxis_title=\"Date time\",\n",
    "    yaxis_title=\"Demand\",\n",
    "    plot_bgcolor='white',\n",
    "    width=800,\n",
    "    height=400,\n",
    "    margin=dict(l=20, r=20, t=35, b=20),\n",
    "    hovermode=\"x\",\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.1,\n",
    "        xanchor=\"left\",\n",
    "        x=0.001\n",
    "    ),\n",
    "    xaxis=dict(linecolor='black',showgrid=True, gridcolor='rgba(0, 0, 0, 0.3)',griddash='dash',mirror=True),\n",
    "    yaxis=dict(linecolor='black',showgrid=True, gridcolor='rgba(0, 0, 0, 0.3)',griddash='dash',mirror=True),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig.write_html('predictions/{}.html'.format(name), auto_open=True)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b8ff1-3e2f-4072-ab0a-4e797b730df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
